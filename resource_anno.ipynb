{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eafd677e-38df-4540-b998-e5ba32978aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXX\n",
      "The 2020 World Series was played at Globe Life Field in Arlington, Texas. This was due to the COVID-19 pandemic, which led to a neutral-site format for the series.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6e3807d-c7cb-46cd-9107-8a930318590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def extract_url_parts(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    # Extract domain and subdomain\n",
    "    domain = parsed_url.netloc\n",
    "    subdomain = ''\n",
    "    if '.' in domain:\n",
    "        parts = domain.split('.')\n",
    "        if len(parts) > 2:\n",
    "            subdomain = '.'.join(parts[:-2])\n",
    "            domain = '.'.join(parts[-2:])\n",
    "    \n",
    "    # Extract path and other word-like substrings\n",
    "    path = parsed_url.path.strip('/')\n",
    "    words_in_path = re.findall(r'\\b\\w+\\b', path)\n",
    "    \n",
    "    # Extract query string parameters and fragments\n",
    "    query_words = re.findall(r'\\b\\w+\\b', parsed_url.query)\n",
    "    fragment_words = re.findall(r'\\b\\w+\\b', parsed_url.fragment)\n",
    "    \n",
    "    # Combine all parts\n",
    "    parts_list = [subdomain, domain] + words_in_path + query_words + fragment_words\n",
    "    # Filter out empty strings and join as a comma-separated list\n",
    "    parts_list = [part for part in parts_list if part]\n",
    "    return ' url keywords: ' + ', '.join(parts_list)\n",
    "\n",
    "\n",
    "def classify_media_type(url):\n",
    "    # Lowercase the URL to make checking easier\n",
    "    url = url.lower()\n",
    "\n",
    "    # Check for common media types\n",
    "    if '.pdf' in url:\n",
    "        return 'PDF'\n",
    "    elif 'youtube.com' in url or 'youtu.be' in url:\n",
    "        return 'YouTube Video'\n",
    "    elif any(ext in url for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "        return 'Image'\n",
    "    elif any(ext in url for ext in ['.mp4', '.mov', '.wmv', '.avi']):\n",
    "        return 'Video'\n",
    "    elif 'wikipedia.org' in url:\n",
    "        return 'Wikipedia Article'\n",
    "    elif 'slideshare.net' in url:\n",
    "        return 'Slide Presentation'\n",
    "    elif '.html' in url or '.htm' in url or urlparse(url).path.endswith('/'):\n",
    "        return 'Web Page'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "def get_resource_description(title, url):\n",
    "    # Extract parts of the URL\n",
    "    url_parts = extract_url_parts(url)\n",
    "    \n",
    "    # Create the prompt with the URL part\n",
    "    prompt = f\"\"\"\n",
    "    You are compiling a list of resources for college faculty and staff on incorporating AI in the classroom or in their workplace.  Write a paragraph describing this resource related to AI, and why it may be helpful to their work. The title of the resource is: {title}. Begin the description with **Description**.  Do not put the url in the description, but here are parts of the url that you may provide helpful information about the resource: {url_parts}.  Also, provide several keywords users can use to quickly see what it is and what it offers.\n",
    "     Begin the list of keywords with **Keywords:**.  Make it a comma-sparated list and format items using title case, where the first letter of each word is capitalized. \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in AI and education resources.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def process_tsv(input_file_path, output_file_path):\n",
    "    with open(input_file_path, mode='r', newline='', encoding='utf-8') as tsvfile:\n",
    "        reader = csv.DictReader(tsvfile, delimiter='\\t')\n",
    "        fieldnames = reader.fieldnames + ['Description', 'Media Type']\n",
    "        \n",
    "        with open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for row in reader:\n",
    "                title = row['Title']\n",
    "                url = row['URL']\n",
    "                description = get_resource_description(title, url)\n",
    "                media_type = classify_media_type(url)\n",
    "                row['Description'] = description\n",
    "                row['Media Type'] = media_type\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Replace 'test.tsv' with the path to your input TSV file and 'test_out.tsv' with the desired output path\n",
    "process_tsv('in_file.tsv', 'out_file.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8e6d6-e375-4aae-9909-902c83bc0ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
